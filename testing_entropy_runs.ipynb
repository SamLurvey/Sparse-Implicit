{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30efb6cf-4396-4e25-b0ea-3d60764b2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "\n",
    "import testing_entropy\n",
    "\n",
    "from models.ffnet import FFNet\n",
    "from models.mlp import MLP\n",
    "from models.siren import SIREN\n",
    "from models.ffnet2 import FFNet2\n",
    "from models.mfn import GaborNetwork\n",
    "from models.gaussian import Gaussian\n",
    "from models.mixed import AlternatingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d980740a-dfe2-4c15-ac9f-70e78f5b2bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on data sample 1: outer/12-2_0-0/AuAu200_170kHz_10C_Iter2_3001.xml_TPCMLDataInterface_1.npy\n",
      "\n",
      "Evaluating SIREN\n",
      "Hyperparameters:\n",
      "  lr: 0.001\n",
      "  in_features: 3\n",
      "  hidden_features: 128\n",
      "  hidden_layers: 3\n",
      "  out_features: 1\n",
      "  device: cuda\n",
      "  max_iters: 1000\n",
      "  nBins: 5\n",
      "  sample_fraction: 0.01\n",
      "  outermost_linear: True\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#normal testing\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#testing with only some nonzero values\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#testing with nonzero values picked each number of steps\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model_grids \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#MLP: base_grid.copy()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#FFNet2: {**base_grid, 'input_scale': [256.0], 'weight_scale': [1.0]}, \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#AlternatingModel: {**base_grid, 'outermost_linear': [True, False]}\u001b[39;00m\n\u001b[1;32m     27\u001b[0m }\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtesting_entropy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_grids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Storage/slurvey/persistent/implicit_sparse_nets/testing_entropy.py:95\u001b[0m, in \u001b[0;36mhyperparameter_grid_search\u001b[0;34m(base_grid, model_grids)\u001b[0m\n\u001b[1;32m     91\u001b[0m     hyperparameter_combinations \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grid\u001b[38;5;241m.\u001b[39mkeys(), values)) \n\u001b[1;32m     92\u001b[0m                                    \u001b[38;5;28;01mfor\u001b[39;00m values \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;241m*\u001b[39mgrid\u001b[38;5;241m.\u001b[39mvalues())]\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hyperparameters \u001b[38;5;129;01min\u001b[39;00m hyperparameter_combinations:\n\u001b[0;32m---> 95\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mModelClass\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m         all_results\u001b[38;5;241m.\u001b[39mextend(results)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Convert results to DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/Storage/slurvey/persistent/implicit_sparse_nets/testing_entropy.py:58\u001b[0m, in \u001b[0;36mevaluate_models\u001b[0;34m(hyperparameters, original_samples, transformed_samples, file_names, model_classes)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m hyperparameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m mse_original, mse_transformed, compression_ratio, training_time \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_iters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnBins\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_fraction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE (original scale): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_original\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE (transformed scale): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse_transformed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/Storage/slurvey/persistent/implicit_sparse_nets/testing_entropy.py:16\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, original_data, transformed_data, max_iters, nBins, sample_fraction)\u001b[0m\n\u001b[1;32m     13\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Train the model on transformed data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m mse_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnBins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnBins\u001b[49m\u001b[43m,\u001b[49m\u001b[43msample_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_fraction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Test the model on the same data\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/Storage/slurvey/persistent/implicit_sparse_nets/models/siren.py:208\u001b[0m, in \u001b[0;36mSIREN.train_entropy\u001b[0;34m(self, data, total_steps, summary_interval, nBins, sample_fraction)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mprint\u001b[39m(step)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Apply entropy sampling\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m sampled_coords, sampled_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentropy_sampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_coords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnBins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnpoint\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m sampled_coords \u001b[38;5;241m=\u001b[39m sampled_coords\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    215\u001b[0m sampled_values \u001b[38;5;241m=\u001b[39m sampled_values\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/Storage/slurvey/persistent/implicit_sparse_nets/models/siren.py:179\u001b[0m, in \u001b[0;36mSIREN.entropy_sampling\u001b[0;34m(self, xyz, points, nBins, npoint)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# select points\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(shuffle_xyz\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 179\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshuffle_feat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbin_min\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbin_width\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnBins\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sampled_hist_list[idx] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    181\u001b[0m         sampled_xyz\u001b[38;5;241m.\u001b[39mappend(shuffle_xyz[i])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(testing_entropy)\n",
    "\n",
    "base_grid = {\n",
    "    'lr': [1e-3],\n",
    "    'in_features': [3],\n",
    "    'hidden_features': [128, 256],\n",
    "    'hidden_layers': [3, 4],\n",
    "    'out_features': [1],\n",
    "    'device': ['cuda' if torch.cuda.is_available() else 'cpu'],\n",
    "    'max_iters': [1000, 2000],\n",
    "    'nBins': [5,10,50,100],\n",
    "    'sample_fraction': [.01, .2, .5,1]\n",
    "\n",
    "}\n",
    "#normal testing\n",
    "#testing with only some nonzero values\n",
    "#testing with nonzero values picked each number of steps\n",
    "\n",
    "model_grids = {\n",
    "    #MLP: base_grid.copy()\n",
    "    #FFNet2: {**base_grid, 'input_scale': [256.0], 'weight_scale': [1.0]}, \n",
    "    #FFNet: {**base_grid, 'fourier_features': [32, 64], 'scale': [10, 20]}\n",
    "    SIREN: {**base_grid, 'outermost_linear': [True, False]}\n",
    "    #GaborNetwork: {**base_grid, 'input_scale': [256.0], 'weight_scale': [1.0], 'alpha': [1.0, 6.0], 'beta': [1.0, 6.0]}\n",
    "    #Gaussian: {**base_grid, 'outermost_linear': [True, False]}\n",
    "    #AlternatingModel: {**base_grid, 'outermost_linear': [True, False]}\n",
    "}\n",
    "\n",
    "testing_entropy.hyperparameter_grid_search(base_grid, model_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1d4b8-c261-4283-a165-3bd514ad5522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3e741-20f1-44f8-a17d-38a967cb309c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
